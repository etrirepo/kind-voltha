2020. 11. 30. (월) 11:27:27 KST
PORTS=8181,8101,55555,5022,2379,9092,6060,6061,6062,9200,5601,16686
OPTIONS
    NAME                           = minimal
    ENABLE_ONOS_EXTRANEOUS_RULES   = no
    WITH_TIMINGS                   = no
    WITH_BBSIM                     = no
    WITH_EFK                       = no
    WITH_TRACING                   = no
    WITH_EAPOL                     = yes
    WITH_DHCP                      = yes
    WITH_IGMP                      = yes
    WITH_CHAOS                     = no
    WITH_ADAPTERS                  = yes
    WITH_SIM_ADAPTERS              = no
    WITH_OPEN_ADAPTERS             = yes
    WITH_PORT_FORWARDS             = yes
    WITH_PPROF                     = no
    WITH_INCREMENTAL_EVTO_UPDATE   = no
    JUST_K8S                       = no
    DEPLOY_K8S                     = no
    INSTALL_ONOS_APPS              = no
    INSTALL_KUBECTL                = yes
    INSTALL_HELM                   = yes
    HELM_USE_UPGRADE               = no
    UPDATE_HELM_REPOS              = yes
    WAIT_ON_DOWN                   = yes
    VOLTHA_DOWN_ON_TIMEOUT         = no
    LEGACY_BBSIM_INDEX             = no
    SCHEDULE_ON_CONTROL_NODES      = no
    CONFIG_SADIS                   = external
    WITH_KAFKA                     = yes
    WITH_RADIUS                    = yes
    WITH_ETCD                      = yes
    WITH_ONOS                      = classic
    WAIT_TIMEOUT                   = 30m
    VOLTHA_LOG_LEVEL               = WARN
    VOLTHA_CHART                   = onf/voltha
    VOLTHA_CHART_VERSION           = 2.5.7
    VOLTHA_BBSIM_CHART             = onf/bbsim
    VOLTHA_BBSIM_CHART_VERSION     = 3.1.0
    BBSIM_SADIS_SERVER_CHART       = bbsim-sadis/bbsim-sadis-server
    BBSIM_SADIS_SERVER_CHART_VERSION = latest
    VOLTHA_TRACING_CHART           = onf/voltha-tracing
    VOLTHA_TRACING_CHART_VERSION   = latest
    NUM_OF_BBSIM                   = 1
    NUM_OF_WORKER_NODES            = 2
    NUM_OF_CONTROLLER_NODES        = 1
    NUM_OF_KAFKA                   = 1
    NUM_OF_ETCD                    = 1
    ELASTICSEARCH_CHART            = elastic/elasticsearch
    ELASTICSEARCH_CHART_VERSION    = latest
    KIBANA_CHART                   = elastic/kibana
    KIBANA_CHART_VERSION           = latest
    FLUENTD_ELASTICSEARCH_CHART    = kiwigrid/fluentd-elasticsearch
    FLUENTD_ELASTICSEARCH_CHART_VERSION = latest
    NUM_OF_OPENONU                 = 1
    VOLTHA_ADAPTER_SIM_CHART       = onf/voltha-adapter-simulated
    VOLTHA_ADAPTER_SIM_CHART_VERSION = latest
    VOLTHA_ADAPTER_OPEN_OLT_CHART  = onf/voltha-adapter-openolt
    VOLTHA_ADAPTER_OPEN_OLT_CHART_VERSION = 2.5.10
    VOLTHA_ADAPTER_OPEN_ONU_CHART  = onf/voltha-adapter-openonu
    VOLTHA_ADAPTER_OPEN_ONU_CHART_VERSION = 2.4.6
    ONOS_CHART                     = onf/onos
    ONOS_CHART_VERSION             = latest
    ONOS_CLASSIC_CHART             = onos/onos-classic
    ONOS_CLASSIC_CHART_VERSION     = 0.1.1
    KAFKA_CHART                    = bitnami/kafka
    KAFKA_CHART_VERSION            = latest
    ETCD_CHART                     = bitnami/etcd
    ETCD_CHART_VERSION             = latest
    RADIUS_CHART                   = onf/freeradius
    RADIUS_CHART_VERSION           = 1.0.1
    ONOS_API_PORT                  = 8181
    ONOS_SSH_PORT                  = 8101
    SADIS_CFG                      = onos-files/onos-sadis-sample.json
    BBSIM_CFG                      = configs/bbsim-sadis-att.yaml
    VOLTHA_API_PORT                = 55555
    VOLTHA_SSH_PORT                = 5022
    VOLTHA_ETCD_PORT               = 2379
    ELASTICSEARCH_PORT             = 9200
    KIBANA_PORT                    = 5601
    VOLTHA_KAFKA_PORT              = 9092
    VOLTHA_PPROF_PORT              = 6060
    OPENOLT_PPROF_PORT             = 6061
    OFAGENT_PPROF_PORT             = 6062
    TRACING_GUI_PORT               = 16686
    VK_RELEASE                     = master
    KIND_VERSION                   = v0.8.1
    VOLTCTL_VERSION                = 1.1.8
    HELM_VERSION                   = v3.2.4
    NUM_OF_ONOS                    = 1
    NUM_OF_ATOMIX                  = 0
    VOLTHA_NS                      = voltha
    ADAPTER_NS                     = voltha
    INFRA_NS                       = default
    BBSIM_NS                       = voltha
    SADIS_BANDWIDTH_PROFILES       = http://bbsim0.voltha.svc:50074/v2/bandwidthprofiles/%s
    SADIS_SUBSCRIBERS              = http://bbsim0.voltha.svc:50074/v2/subscribers/%s
    PF_ADDRESS                     = 0.0.0.0
INSTALL NAME: minimal
+ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "bbsim-sadis" chart repository
...Successfully got an update from the "kiwigrid" chart repository
...Successfully got an update from the "etcd" chart repository
...Successfully got an update from the "atomix" chart repository
...Successfully got an update from the "incubator" chart repository
...Successfully got an update from the "elastic" chart repository
...Successfully got an update from the "onos" chart repository
...Successfully got an update from the "stable" chart repository
...Successfully got an update from the "onf" chart repository
...Successfully got an update from the "bitnami" chart repository
Update Complete. ⎈ Happy Helming!⎈ 
Resolved helm charts and versions:
    onf/voltha:2.5.7
    onf/bbsim:3.1.0
    onf/voltha-tracing:1.0.0
    onf/voltha-adapter-simulated:2.3.0
    onf/voltha-adapter-openolt:2.5.10
    onf/voltha-adapter-openonu:2.4.6
    onf/onos:3.0.1
    onos/onos-classic:0.1.1
    bitnami/kafka:12.2.1
    elastic/elasticsearch:7.10.0
    elastic/kibana:7.10.0
    kiwigrid/fluentd-elasticsearch:9.6.2
    bbsim-sadis/bbsim-sadis-server:1.1.0
    onf/freeradius:1.0.1
+ helm install -f /tmp/tmp.wG3d26Vd9J --create-namespace --set auth.rbac.enabled=false,persistence.enabled=false,statefulset.replicaCount=1 --set defaults.log_level=WARN --namespace default --set defaults.image_tag=null,images.onos.tag=4.1.4 etcd bitnami/etcd
NAME: etcd
LAST DEPLOYED: Mon Nov 30 11:27:41 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
** Please be patient while the chart is being deployed **

etcd can be accessed via port 2379 on the following DNS name from within your cluster:

    etcd.default.svc.cluster.local

To set a key run the following command:

    export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=etcd,app.kubernetes.io/instance=etcd" -o jsonpath="{.items[0].metadata.name}")
    kubectl exec -it $POD_NAME -- etcdctl put /message Hello

To get a key run the following command:

    export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=etcd,app.kubernetes.io/instance=etcd" -o jsonpath="{.items[0].metadata.name}")
    kubectl exec -it $POD_NAME -- etcdctl get /message

To connect to your etcd server from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/etcd 2379:2379 &
    echo "etcd URL: http://127.0.0.1:2379"
+ helm install -f /tmp/tmp.iIXYuX3LqV --create-namespace -f /tmp/tmp.GPJ5nWtER3 --set defaults.log_level=WARN --namespace default --set defaults.image_tag=null,images.onos.tag=4.1.4 kafka bitnami/kafka
NAME: kafka
LAST DEPLOYED: Mon Nov 30 11:29:02 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
** Please be patient while the chart is being deployed **

Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:

    kafka.default.svc.cluster.local

Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:

    kafka-0.kafka-headless.default.svc.cluster.local:9092

To create a pod that you can use as a Kafka client run the following commands:

    kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:2.6.0-debian-10-r78 --namespace default --command -- sleep infinity
    kubectl exec --tty -i kafka-client --namespace default -- bash

    PRODUCER:
        kafka-console-producer.sh \
            
            --broker-list kafka-0.kafka-headless.default.svc.cluster.local:9092 \
            --topic test

    CONSUMER:
        kafka-console-consumer.sh \
            
            --bootstrap-server kafka.default.svc.cluster.local:9092 \
            --topic test \
            --from-beginning
---
# Copyright 2019 Ciena Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# IMAGE SELECTION
# ---------------
# By default no defaults are set and the image tags specified in the helm
# charts will be used. If you would like to use the images generated from the
# HEAD of the "master" git branches, then uncomment this below block and
# set "<VALUE>" to "master". Similarly, if you want to use the images
# generated from the HEAD of the "voltha-2.1" git branches, then uncomment
# this block and replace "<VALUE>" with "voltha-2.1".
defaults:
  image_tag: master
  image_pullPolicy: Always

private_etcd_cluster: false
private_kafka_cluster: false

# OPENONU-ADAPTER IMPLEMENTATION
# ------------------------------
# There are currently two implementations of OPENONU-ADAPTER: the original
# written in Python and the reimplementation written in Go. The variable
# `use_openonu_adapter_go` can be used to optionally use the new Go
# implementation. This is done by setting that value to `true`.
#
# Along with this change you will also may need to set the Docker image
# information below (search for START_OPENONU_ADAPTER_GO).
use_openonu_adapter_go: false

images:
  onos:
    repository: voltha/voltha-onos
    # IMAGE_SELECTION
    # ---------------
    # The helm chart used to deploy ONOS is the public ONOS helm chart so,
    # there is a need to specify the exact image repository and image tag.
    # If you would like to use the "master", "voltha-2.1", or other image
    # just replace the "tag" value below.
    tag: master

# IMAGE_SELECTION
# ---------------
# Below are a list of all the images utilized by kind-voltha. This list is
# provided as a conveinence if you would like to override on a per image
# basis. If you are using the defaults, master, or voltha-2.1 branch there
# is no need to utilize this list.
#  adapter_open_olt:
#    repository: etrirepository/voltha-openolt-adapter
#    tag: dev
  adapter_open_onu:
    repository: ywra/voltha-openonu-adapter
    tag: dev
#  adapter_simulated_olt:
#    repository: voltha/voltha-adapter-simulated-olt
#    tag: 2.1.1
#  adapter_simulated_onu:
#    repository: voltha/voltha-adapter-simulated-onu
#    tag: 2.1.1
  bbsim:
    repository: ywra/bbsim
    tag: dev
#  ofagent:
#    repository: etrirepository/voltha-ofagent-go
#    tag: dev
#  rw_core:
#    repository: etrirepository/voltha-rw-core
#    tag: dev
# START_OPENONU_ADAPTER_GO - Uncomment the following block to use the
# Go implementation of the openonu-adapter
#  adapter_open_onu_go:
#    repository: voltha-openonu-adapter-go
#    tag: master
# END_OPENONU_ADAPTER_GO

etcd:
  extraEnv:
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "1"
    - name: ETCD_SNAPSHOT_COUNT
      value: "100000"
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "100"
    - name: ETCD_ELECTION_TIMEOUT
      value: "1000"
    - name: ETCD_MAX_SNAPSHOTS
      value: "5"
    - name: ETCD_QUOTA_BACKEND_BYTES
      value: "0"
    - name: ETCD_MAX_REQUEST_BYTES
      value: "1572864"
    - name: ETCD_GRPC_KEEPALIVE_MIN_TIME
      value: "5s"
    - name: ETCD_GRPC_KEEPALIVE_TIMEOUT
      value: "5s"
    - name: ETCD_DEBUG
      value: "false"

kafka:
  zookeeper:
    persistence:
      enabled: false
  persistence:
    enabled: false
  envOverrides:
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # yamllint disable-line rule:line-length
    KAFKA_LOG4J.LOGGERS: "kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka=ERROR,kafka.controller=ERROR"
    KAFKA_LOG_RETENTION_HOURS: 1
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# voltha:
#   fullNameOverride: voltha

# open-olt:
#   fullNameOverride: voltha-adapter-openolt

# open-onu:
#   fullNameOverride: voltha-adapter-openonu

onos:
  image:
    repository: voltha/voltha-onos
    tag: master
    pullPolicy: Always
  onos_env:
    - name: POD_IP
      valueFrom:
      fieldRef:
        fieldPath: status.podIP
    - name: NAMESPACE
      valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
    - name: ONOS_APPS
      value: "drivers,openflow-base,hostprovider"
  apps:
    - org.onosproject.lldpprovider
    - org.onosproject.openflow-base
    - org.onosproject.gui2
    - org.onosproject.drivers
    - org.onosproject.mcast
    - org.opencord.kafka
    - org.opencord.sadis
    - org.opencord.dhcpl2relay
    - org.opencord.maclearner
    - org.opencord.igmpproxy
    - org.opencord.mcast
    - org.opencord.olt
    - org.opencord.aaa
  # No persistent volume in Atomix to have clean state for each re-deploy of ONOS
  atomix:
    persistence:
      enabled: false

# Customization for BBSIM
bbsim:
  nni: 1
  pon: 1
  onu: 1
  sadisFormat: "att"
  kafkaEventTopic: "bbsim"
  enableEvents: false

# Customization for BBSIM SADIS Servier
sadis:
  config:
    bbsim_sadis_server:
      sleep_time: 5s

# START EFK Setup to push voltha logs
# elasticstack config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/elasticsearch
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  # set cpu and memory configuration
  resources:
    requests:
      cpu: "400m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  # setup persistence volume.By default persistence volumeclaim is disabled
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 5Gi
  persistence:
    enabled: false
  # setup cluster health status as yellow
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

# kibana config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/kibana
kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"

# fluentd-elasticsearch config
# ref: https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch
fluentd-elasticsearch:
  elasticsearch:
    # set elasticsearch host
    hosts: ["elasticsearch-master:9200"]
    sslVerify: false

# Increase maxTraces to retain Traces for longer duration
# But tracing pod will consume more memory
tracing:
  maxTraces: 500000

# SHOCK THE MONKEY OR LET LOSE THE DOGS OF WAR
# The VOLTHA charts have support for adding extra labels to deployments and
# pods. These extra labels can be used to integrate with other utilities
# such as kube-monkey to add a bit of chaos to the cluster. Below are some
# settings that can be uncommented to opt-in VOLTHA deployments/pods to
# kube-monkey. For example, if you want ALL deployments and pods to opt-in
# then uncomment the `extra_deployment_labels` and `extra_pod_label` blocks.
# If you want to be more selected then comment the blocks that pertain to the
# targets you care about.

# extra_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# extra_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
image:
  repository: voltha/voltha-onos
  tag: master
  pullPolicy: Always
onos_env:
  - name: POD_IP
    valueFrom:
    fieldRef:
      fieldPath: status.podIP
  - name: NAMESPACE
    valueFrom:
    fieldRef:
      fieldPath: metadata.namespace
  - name: ONOS_APPS
    value: "drivers,openflow-base,hostprovider"
apps:
  - org.onosproject.lldpprovider
  - org.onosproject.openflow-base
  - org.onosproject.gui2
  - org.onosproject.drivers
  - org.onosproject.mcast
  - org.opencord.kafka
  - org.opencord.sadis
  - org.opencord.dhcpl2relay
  - org.opencord.maclearner
  - org.opencord.igmpproxy
  - org.opencord.mcast
  - org.opencord.olt
  - org.opencord.aaa
# No persistent volume in Atomix to have clean state for each re-deploy of ONOS
atomix:
  persistence:
    enabled: false
+ helm install -f /tmp/tmp.PkKvefjjYE --create-namespace --set image.pullPolicy=Always,image.repository=voltha/voltha-onos,image.tag=4.1.4,replicas=1,atomix.replicas=0 --set defaults.log_level=WARN --namespace default --version 0.1.1 --set defaults.image_tag=null,images.onos.tag=4.1.4 onos onos/onos-classic
NAME: onos
LAST DEPLOYED: Mon Nov 30 11:30:26 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
+ mkdir -p ./onos-files
+ grep ACTIVE
+ curl --fail -sSL --user karaf:karaf -X GET http://127.0.0.1:8181/onos/v1/applications/org.opencord.kafka
curl: (7) Failed to connect to 127.0.0.1 port 8181: Connection refused
+ curl --fail -sSL --user karaf:karaf -X GET http://127.0.0.1:8181/onos/v1/applications/org.opencord.kafka
+ grep ACTIVE
{"name":"org.opencord.kafka","id":192,"version":"2.3.2","category":"Integration","description":"Integration with Kafka event bus","readme":"Integration with Kafka event bus","origin":"ONF","url":"http://opencord.org","featuresRepo":"mvn:org.opencord/kafka/2.3.2/xml/features","state":"ACTIVE","features":["kafka"],"permissions":[],"requiredApps":[]}
+ curl -sSL --user karaf:karaf -w '%{http_code}' -o /tmp/tmp.soJPWpuurB -X POST --fail -H Content-Type:application/json http://127.0.0.1:8181/onos/v1/network/configuration/apps/org.opencord.kafka --data '{"kafka":{"bootstrapServers":"kafka.default.svc:9092"}}'
RESPONSE CODE: 200
ERROR CODE: 0
+ curl --fail -sSL --user karaf:karaf -X GET http://127.0.0.1:8181/onos/v1/applications/org.opencord.dhcpl2relay
+ grep ACTIVE
{"name":"org.opencord.dhcpl2relay","id":194,"version":"2.1.0","category":"default","description":"DHCP L2 Relay Agent Application.","readme":"DHCP L2 Relay Agent Application.","origin":"Open Networking Foundation","url":"http://onosproject.org","featuresRepo":"mvn:org.opencord/dhcpl2relay-app/2.1.0/xml/features","state":"ACTIVE","features":["dhcpl2relay-app"],"permissions":[],"requiredApps":["org.opencord.sadis"]}
+ curl -sSL --user karaf:karaf -w '%{http_code}' -o /tmp/tmp.asYMMf8arT -X POST --fail -H Content-Type:application/json http://127.0.0.1:8181/onos/v1/network/configuration/apps/org.opencord.dhcpl2relay --data @onos-files/onos-dhcpl2relay.json
RESPONSE CODE: 200
ERROR CODE: 0
+ curl --fail -sSL --user karaf:karaf -X GET http://127.0.0.1:8181/onos/v1/applications/org.opencord.olt
+ grep ACTIVE
{"name":"org.opencord.olt","id":195,"version":"4.1.3","category":"Traffic Steering","description":"CORD OLT Access management application","readme":"CORD OLT Access management application","origin":"Open Networking Foundation","url":"http://onosproject.org","featuresRepo":"mvn:org.opencord/olt-app/4.1.3/xml/features","state":"ACTIVE","features":["olt-app"],"permissions":[],"requiredApps":["org.opencord.sadis"]}
+ curl -sSL --user karaf:karaf -w '%{http_code}' -o /tmp/tmp.mvwNr6Gcvi -X POST --fail -H Content-Type:application/json http://127.0.0.1:8181/onos/v1/configuration/org.opencord.olt.impl.OltFlowService --data '{"enableEapol":true}'
RESPONSE CODE: 200
ERROR CODE: 0
+ curl -sSL --user karaf:karaf -w '%{http_code}' -o /tmp/tmp.406E8gSIPq -X POST --fail -H Content-Type:application/json http://127.0.0.1:8181/onos/v1/configuration/org.opencord.olt.impl.OltFlowService --data '{"enableDhcpOnProvisioning":true}'
RESPONSE CODE: 200
ERROR CODE: 0
+ curl -sSL --user karaf:karaf -w '%{http_code}' -o /tmp/tmp.BxCMKZitjt -X POST --fail -H Content-Type:application/json http://127.0.0.1:8181/onos/v1/configuration/org.opencord.olt.impl.OltFlowService --data '{"enableIgmpOnProvisioning":true}'
RESPONSE CODE: 200
ERROR CODE: 0
---
# Copyright 2019 Ciena Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# IMAGE SELECTION
# ---------------
# By default no defaults are set and the image tags specified in the helm
# charts will be used. If you would like to use the images generated from the
# HEAD of the "master" git branches, then uncomment this below block and
# set "<VALUE>" to "master". Similarly, if you want to use the images
# generated from the HEAD of the "voltha-2.1" git branches, then uncomment
# this block and replace "<VALUE>" with "voltha-2.1".
defaults:
  image_tag: master
  image_pullPolicy: Always

private_etcd_cluster: false
private_kafka_cluster: false

# OPENONU-ADAPTER IMPLEMENTATION
# ------------------------------
# There are currently two implementations of OPENONU-ADAPTER: the original
# written in Python and the reimplementation written in Go. The variable
# `use_openonu_adapter_go` can be used to optionally use the new Go
# implementation. This is done by setting that value to `true`.
#
# Along with this change you will also may need to set the Docker image
# information below (search for START_OPENONU_ADAPTER_GO).
use_openonu_adapter_go: false

images:
  onos:
    repository: voltha/voltha-onos
    # IMAGE_SELECTION
    # ---------------
    # The helm chart used to deploy ONOS is the public ONOS helm chart so,
    # there is a need to specify the exact image repository and image tag.
    # If you would like to use the "master", "voltha-2.1", or other image
    # just replace the "tag" value below.
    tag: master

# IMAGE_SELECTION
# ---------------
# Below are a list of all the images utilized by kind-voltha. This list is
# provided as a conveinence if you would like to override on a per image
# basis. If you are using the defaults, master, or voltha-2.1 branch there
# is no need to utilize this list.
#  adapter_open_olt:
#    repository: etrirepository/voltha-openolt-adapter
#    tag: dev
  adapter_open_onu:
    repository: ywra/voltha-openonu-adapter
    tag: dev
#  adapter_simulated_olt:
#    repository: voltha/voltha-adapter-simulated-olt
#    tag: 2.1.1
#  adapter_simulated_onu:
#    repository: voltha/voltha-adapter-simulated-onu
#    tag: 2.1.1
  bbsim:
    repository: ywra/bbsim
    tag: dev
#  ofagent:
#    repository: etrirepository/voltha-ofagent-go
#    tag: dev
#  rw_core:
#    repository: etrirepository/voltha-rw-core
#    tag: dev
# START_OPENONU_ADAPTER_GO - Uncomment the following block to use the
# Go implementation of the openonu-adapter
#  adapter_open_onu_go:
#    repository: voltha-openonu-adapter-go
#    tag: master
# END_OPENONU_ADAPTER_GO

etcd:
  extraEnv:
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "1"
    - name: ETCD_SNAPSHOT_COUNT
      value: "100000"
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "100"
    - name: ETCD_ELECTION_TIMEOUT
      value: "1000"
    - name: ETCD_MAX_SNAPSHOTS
      value: "5"
    - name: ETCD_QUOTA_BACKEND_BYTES
      value: "0"
    - name: ETCD_MAX_REQUEST_BYTES
      value: "1572864"
    - name: ETCD_GRPC_KEEPALIVE_MIN_TIME
      value: "5s"
    - name: ETCD_GRPC_KEEPALIVE_TIMEOUT
      value: "5s"
    - name: ETCD_DEBUG
      value: "false"

kafka:
  zookeeper:
    persistence:
      enabled: false
  persistence:
    enabled: false
  envOverrides:
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # yamllint disable-line rule:line-length
    KAFKA_LOG4J.LOGGERS: "kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka=ERROR,kafka.controller=ERROR"
    KAFKA_LOG_RETENTION_HOURS: 1
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# voltha:
#   fullNameOverride: voltha

# open-olt:
#   fullNameOverride: voltha-adapter-openolt

# open-onu:
#   fullNameOverride: voltha-adapter-openonu

onos:
  image:
    repository: voltha/voltha-onos
    tag: master
    pullPolicy: Always
  onos_env:
    - name: POD_IP
      valueFrom:
      fieldRef:
        fieldPath: status.podIP
    - name: NAMESPACE
      valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
    - name: ONOS_APPS
      value: "drivers,openflow-base,hostprovider"
  apps:
    - org.onosproject.lldpprovider
    - org.onosproject.openflow-base
    - org.onosproject.gui2
    - org.onosproject.drivers
    - org.onosproject.mcast
    - org.opencord.kafka
    - org.opencord.sadis
    - org.opencord.dhcpl2relay
    - org.opencord.maclearner
    - org.opencord.igmpproxy
    - org.opencord.mcast
    - org.opencord.olt
    - org.opencord.aaa
  # No persistent volume in Atomix to have clean state for each re-deploy of ONOS
  atomix:
    persistence:
      enabled: false

# Customization for BBSIM
bbsim:
  nni: 1
  pon: 1
  onu: 1
  sadisFormat: "att"
  kafkaEventTopic: "bbsim"
  enableEvents: false

# Customization for BBSIM SADIS Servier
sadis:
  config:
    bbsim_sadis_server:
      sleep_time: 5s

# START EFK Setup to push voltha logs
# elasticstack config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/elasticsearch
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  # set cpu and memory configuration
  resources:
    requests:
      cpu: "400m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  # setup persistence volume.By default persistence volumeclaim is disabled
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 5Gi
  persistence:
    enabled: false
  # setup cluster health status as yellow
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

# kibana config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/kibana
kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"

# fluentd-elasticsearch config
# ref: https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch
fluentd-elasticsearch:
  elasticsearch:
    # set elasticsearch host
    hosts: ["elasticsearch-master:9200"]
    sslVerify: false

# Increase maxTraces to retain Traces for longer duration
# But tracing pod will consume more memory
tracing:
  maxTraces: 500000

# SHOCK THE MONKEY OR LET LOSE THE DOGS OF WAR
# The VOLTHA charts have support for adding extra labels to deployments and
# pods. These extra labels can be used to integrate with other utilities
# such as kube-monkey to add a bit of chaos to the cluster. Below are some
# settings that can be uncommented to opt-in VOLTHA deployments/pods to
# kube-monkey. For example, if you want ALL deployments and pods to opt-in
# then uncomment the `extra_deployment_labels` and `extra_pod_label` blocks.
# If you want to be more selected then comment the blocks that pertain to the
# targets you care about.

# extra_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# extra_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
+ helm install -f /tmp/tmp.8AYCyUP9py --create-namespace --set therecanbeonlyone=true --set services.etcd.service=etcd.default.svc --set services.etcd.port=2379 --set services.etcd.address=etcd.default.svc:2379 --set kafka_broker=kafka.default.svc:9092 --set services.kafka.adapter.service=kafka.default.svc --set services.kafka.adapter.port=9092 --set services.kafka.cluster.service=kafka.default.svc --set services.kafka.cluster.port=9092 --set services.kafka.adapter.address=kafka.default.svc:9092 --set services.kafka.cluster.address=kafka.default.svc:9092 --set 'services.controller[0].service=onos-onos-classic-0.onos-onos-classic-hs.default.svc' --set 'services.controller[0].port=6653' --set 'services.controller[0].address=onos-onos-classic-0.onos-onos-classic-hs.default.svc:6653' --set defaults.log_level=WARN --namespace voltha --version 2.5.7 --set defaults.image_tag=null,images.onos.tag=4.1.4 voltha onf/voltha
NAME: voltha
LAST DEPLOYED: Mon Nov 30 11:33:30 2020
NAMESPACE: voltha
STATUS: deployed
REVISION: 1
TEST SUITE: None
---
# Copyright 2019 Ciena Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# IMAGE SELECTION
# ---------------
# By default no defaults are set and the image tags specified in the helm
# charts will be used. If you would like to use the images generated from the
# HEAD of the "master" git branches, then uncomment this below block and
# set "<VALUE>" to "master". Similarly, if you want to use the images
# generated from the HEAD of the "voltha-2.1" git branches, then uncomment
# this block and replace "<VALUE>" with "voltha-2.1".
defaults:
  image_tag: master
  image_pullPolicy: Always

private_etcd_cluster: false
private_kafka_cluster: false

# OPENONU-ADAPTER IMPLEMENTATION
# ------------------------------
# There are currently two implementations of OPENONU-ADAPTER: the original
# written in Python and the reimplementation written in Go. The variable
# `use_openonu_adapter_go` can be used to optionally use the new Go
# implementation. This is done by setting that value to `true`.
#
# Along with this change you will also may need to set the Docker image
# information below (search for START_OPENONU_ADAPTER_GO).
use_openonu_adapter_go: false

images:
  onos:
    repository: voltha/voltha-onos
    # IMAGE_SELECTION
    # ---------------
    # The helm chart used to deploy ONOS is the public ONOS helm chart so,
    # there is a need to specify the exact image repository and image tag.
    # If you would like to use the "master", "voltha-2.1", or other image
    # just replace the "tag" value below.
    tag: master

# IMAGE_SELECTION
# ---------------
# Below are a list of all the images utilized by kind-voltha. This list is
# provided as a conveinence if you would like to override on a per image
# basis. If you are using the defaults, master, or voltha-2.1 branch there
# is no need to utilize this list.
#  adapter_open_olt:
#    repository: etrirepository/voltha-openolt-adapter
#    tag: dev
  adapter_open_onu:
    repository: ywra/voltha-openonu-adapter
    tag: dev
#  adapter_simulated_olt:
#    repository: voltha/voltha-adapter-simulated-olt
#    tag: 2.1.1
#  adapter_simulated_onu:
#    repository: voltha/voltha-adapter-simulated-onu
#    tag: 2.1.1
  bbsim:
    repository: ywra/bbsim
    tag: dev
#  ofagent:
#    repository: etrirepository/voltha-ofagent-go
#    tag: dev
#  rw_core:
#    repository: etrirepository/voltha-rw-core
#    tag: dev
# START_OPENONU_ADAPTER_GO - Uncomment the following block to use the
# Go implementation of the openonu-adapter
#  adapter_open_onu_go:
#    repository: voltha-openonu-adapter-go
#    tag: master
# END_OPENONU_ADAPTER_GO

etcd:
  extraEnv:
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "1"
    - name: ETCD_SNAPSHOT_COUNT
      value: "100000"
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "100"
    - name: ETCD_ELECTION_TIMEOUT
      value: "1000"
    - name: ETCD_MAX_SNAPSHOTS
      value: "5"
    - name: ETCD_QUOTA_BACKEND_BYTES
      value: "0"
    - name: ETCD_MAX_REQUEST_BYTES
      value: "1572864"
    - name: ETCD_GRPC_KEEPALIVE_MIN_TIME
      value: "5s"
    - name: ETCD_GRPC_KEEPALIVE_TIMEOUT
      value: "5s"
    - name: ETCD_DEBUG
      value: "false"

kafka:
  zookeeper:
    persistence:
      enabled: false
  persistence:
    enabled: false
  envOverrides:
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # yamllint disable-line rule:line-length
    KAFKA_LOG4J.LOGGERS: "kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka=ERROR,kafka.controller=ERROR"
    KAFKA_LOG_RETENTION_HOURS: 1
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# voltha:
#   fullNameOverride: voltha

# open-olt:
#   fullNameOverride: voltha-adapter-openolt

# open-onu:
#   fullNameOverride: voltha-adapter-openonu

onos:
  image:
    repository: voltha/voltha-onos
    tag: master
    pullPolicy: Always
  onos_env:
    - name: POD_IP
      valueFrom:
      fieldRef:
        fieldPath: status.podIP
    - name: NAMESPACE
      valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
    - name: ONOS_APPS
      value: "drivers,openflow-base,hostprovider"
  apps:
    - org.onosproject.lldpprovider
    - org.onosproject.openflow-base
    - org.onosproject.gui2
    - org.onosproject.drivers
    - org.onosproject.mcast
    - org.opencord.kafka
    - org.opencord.sadis
    - org.opencord.dhcpl2relay
    - org.opencord.maclearner
    - org.opencord.igmpproxy
    - org.opencord.mcast
    - org.opencord.olt
    - org.opencord.aaa
  # No persistent volume in Atomix to have clean state for each re-deploy of ONOS
  atomix:
    persistence:
      enabled: false

# Customization for BBSIM
bbsim:
  nni: 1
  pon: 1
  onu: 1
  sadisFormat: "att"
  kafkaEventTopic: "bbsim"
  enableEvents: false

# Customization for BBSIM SADIS Servier
sadis:
  config:
    bbsim_sadis_server:
      sleep_time: 5s

# START EFK Setup to push voltha logs
# elasticstack config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/elasticsearch
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  # set cpu and memory configuration
  resources:
    requests:
      cpu: "400m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  # setup persistence volume.By default persistence volumeclaim is disabled
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 5Gi
  persistence:
    enabled: false
  # setup cluster health status as yellow
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

# kibana config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/kibana
kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"

# fluentd-elasticsearch config
# ref: https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch
fluentd-elasticsearch:
  elasticsearch:
    # set elasticsearch host
    hosts: ["elasticsearch-master:9200"]
    sslVerify: false

# Increase maxTraces to retain Traces for longer duration
# But tracing pod will consume more memory
tracing:
  maxTraces: 500000

# SHOCK THE MONKEY OR LET LOSE THE DOGS OF WAR
# The VOLTHA charts have support for adding extra labels to deployments and
# pods. These extra labels can be used to integrate with other utilities
# such as kube-monkey to add a bit of chaos to the cluster. Below are some
# settings that can be uncommented to opt-in VOLTHA deployments/pods to
# kube-monkey. For example, if you want ALL deployments and pods to opt-in
# then uncomment the `extra_deployment_labels` and `extra_pod_label` blocks.
# If you want to be more selected then comment the blocks that pertain to the
# targets you care about.

# extra_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# extra_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
+ helm install -f /tmp/tmp.26Z9JatkKk --create-namespace --set services.etcd.service=etcd.default.svc --set services.etcd.port=2379 --set services.etcd.address=etcd.default.svc:2379 --set kafka_broker=kafka.default.svc:9092 --set services.kafka.adapter.service=kafka.default.svc --set services.kafka.adapter.port=9092 --set services.kafka.cluster.service=kafka.default.svc --set services.kafka.cluster.port=9092 --set services.kafka.adapter.address=kafka.default.svc:9092 --set services.kafka.cluster.address=kafka.default.svc:9092 --set defaults.log_level=WARN --namespace voltha --version 2.5.10 --set defaults.image_tag=null,images.onos.tag=4.1.4 open-olt onf/voltha-adapter-openolt
NAME: open-olt
LAST DEPLOYED: Mon Nov 30 11:34:03 2020
NAMESPACE: voltha
STATUS: deployed
REVISION: 1
TEST SUITE: None
---
# Copyright 2019 Ciena Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# IMAGE SELECTION
# ---------------
# By default no defaults are set and the image tags specified in the helm
# charts will be used. If you would like to use the images generated from the
# HEAD of the "master" git branches, then uncomment this below block and
# set "<VALUE>" to "master". Similarly, if you want to use the images
# generated from the HEAD of the "voltha-2.1" git branches, then uncomment
# this block and replace "<VALUE>" with "voltha-2.1".
defaults:
  image_tag: master
  image_pullPolicy: Always

private_etcd_cluster: false
private_kafka_cluster: false

# OPENONU-ADAPTER IMPLEMENTATION
# ------------------------------
# There are currently two implementations of OPENONU-ADAPTER: the original
# written in Python and the reimplementation written in Go. The variable
# `use_openonu_adapter_go` can be used to optionally use the new Go
# implementation. This is done by setting that value to `true`.
#
# Along with this change you will also may need to set the Docker image
# information below (search for START_OPENONU_ADAPTER_GO).
use_openonu_adapter_go: false

images:
  onos:
    repository: voltha/voltha-onos
    # IMAGE_SELECTION
    # ---------------
    # The helm chart used to deploy ONOS is the public ONOS helm chart so,
    # there is a need to specify the exact image repository and image tag.
    # If you would like to use the "master", "voltha-2.1", or other image
    # just replace the "tag" value below.
    tag: master

# IMAGE_SELECTION
# ---------------
# Below are a list of all the images utilized by kind-voltha. This list is
# provided as a conveinence if you would like to override on a per image
# basis. If you are using the defaults, master, or voltha-2.1 branch there
# is no need to utilize this list.
#  adapter_open_olt:
#    repository: etrirepository/voltha-openolt-adapter
#    tag: dev
  adapter_open_onu:
    repository: ywra/voltha-openonu-adapter
    tag: dev
#  adapter_simulated_olt:
#    repository: voltha/voltha-adapter-simulated-olt
#    tag: 2.1.1
#  adapter_simulated_onu:
#    repository: voltha/voltha-adapter-simulated-onu
#    tag: 2.1.1
  bbsim:
    repository: ywra/bbsim
    tag: dev
#  ofagent:
#    repository: etrirepository/voltha-ofagent-go
#    tag: dev
#  rw_core:
#    repository: etrirepository/voltha-rw-core
#    tag: dev
# START_OPENONU_ADAPTER_GO - Uncomment the following block to use the
# Go implementation of the openonu-adapter
#  adapter_open_onu_go:
#    repository: voltha-openonu-adapter-go
#    tag: master
# END_OPENONU_ADAPTER_GO

etcd:
  extraEnv:
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "1"
    - name: ETCD_SNAPSHOT_COUNT
      value: "100000"
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "100"
    - name: ETCD_ELECTION_TIMEOUT
      value: "1000"
    - name: ETCD_MAX_SNAPSHOTS
      value: "5"
    - name: ETCD_QUOTA_BACKEND_BYTES
      value: "0"
    - name: ETCD_MAX_REQUEST_BYTES
      value: "1572864"
    - name: ETCD_GRPC_KEEPALIVE_MIN_TIME
      value: "5s"
    - name: ETCD_GRPC_KEEPALIVE_TIMEOUT
      value: "5s"
    - name: ETCD_DEBUG
      value: "false"

kafka:
  zookeeper:
    persistence:
      enabled: false
  persistence:
    enabled: false
  envOverrides:
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # yamllint disable-line rule:line-length
    KAFKA_LOG4J.LOGGERS: "kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka=ERROR,kafka.controller=ERROR"
    KAFKA_LOG_RETENTION_HOURS: 1
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# voltha:
#   fullNameOverride: voltha

# open-olt:
#   fullNameOverride: voltha-adapter-openolt

# open-onu:
#   fullNameOverride: voltha-adapter-openonu

onos:
  image:
    repository: voltha/voltha-onos
    tag: master
    pullPolicy: Always
  onos_env:
    - name: POD_IP
      valueFrom:
      fieldRef:
        fieldPath: status.podIP
    - name: NAMESPACE
      valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
    - name: ONOS_APPS
      value: "drivers,openflow-base,hostprovider"
  apps:
    - org.onosproject.lldpprovider
    - org.onosproject.openflow-base
    - org.onosproject.gui2
    - org.onosproject.drivers
    - org.onosproject.mcast
    - org.opencord.kafka
    - org.opencord.sadis
    - org.opencord.dhcpl2relay
    - org.opencord.maclearner
    - org.opencord.igmpproxy
    - org.opencord.mcast
    - org.opencord.olt
    - org.opencord.aaa
  # No persistent volume in Atomix to have clean state for each re-deploy of ONOS
  atomix:
    persistence:
      enabled: false

# Customization for BBSIM
bbsim:
  nni: 1
  pon: 1
  onu: 1
  sadisFormat: "att"
  kafkaEventTopic: "bbsim"
  enableEvents: false

# Customization for BBSIM SADIS Servier
sadis:
  config:
    bbsim_sadis_server:
      sleep_time: 5s

# START EFK Setup to push voltha logs
# elasticstack config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/elasticsearch
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  # set cpu and memory configuration
  resources:
    requests:
      cpu: "400m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  # setup persistence volume.By default persistence volumeclaim is disabled
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 5Gi
  persistence:
    enabled: false
  # setup cluster health status as yellow
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

# kibana config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/kibana
kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"

# fluentd-elasticsearch config
# ref: https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch
fluentd-elasticsearch:
  elasticsearch:
    # set elasticsearch host
    hosts: ["elasticsearch-master:9200"]
    sslVerify: false

# Increase maxTraces to retain Traces for longer duration
# But tracing pod will consume more memory
tracing:
  maxTraces: 500000

# SHOCK THE MONKEY OR LET LOSE THE DOGS OF WAR
# The VOLTHA charts have support for adding extra labels to deployments and
# pods. These extra labels can be used to integrate with other utilities
# such as kube-monkey to add a bit of chaos to the cluster. Below are some
# settings that can be uncommented to opt-in VOLTHA deployments/pods to
# kube-monkey. For example, if you want ALL deployments and pods to opt-in
# then uncomment the `extra_deployment_labels` and `extra_pod_label` blocks.
# If you want to be more selected then comment the blocks that pertain to the
# targets you care about.

# extra_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# extra_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
+ helm install -f /tmp/tmp.9vIbbgBXy8 --create-namespace --set services.etcd.service=etcd.default.svc --set services.etcd.port=2379 --set services.etcd.address=etcd.default.svc:2379 --set kafka_broker=kafka.default.svc:9092 --set services.kafka.adapter.service=kafka.default.svc --set services.kafka.adapter.port=9092 --set services.kafka.cluster.service=kafka.default.svc --set services.kafka.cluster.port=9092 --set services.kafka.adapter.address=kafka.default.svc:9092 --set services.kafka.cluster.address=kafka.default.svc:9092 --set replicas.adapter_open_onu=1 --set defaults.log_level=WARN --namespace voltha --version 2.4.6 --set defaults.image_tag=null,images.onos.tag=4.1.4 open-onu onf/voltha-adapter-openonu
NAME: open-onu
LAST DEPLOYED: Mon Nov 30 11:34:04 2020
NAMESPACE: voltha
STATUS: deployed
REVISION: 1
TEST SUITE: None
+ kubectl -n voltha delete --ignore-not-found configmap kube-config
+ kubectl -n voltha create configmap kube-config --from-file=kube_config=
error: file path for key name kube_config missing
---
# Copyright 2019 Ciena Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# IMAGE SELECTION
# ---------------
# By default no defaults are set and the image tags specified in the helm
# charts will be used. If you would like to use the images generated from the
# HEAD of the "master" git branches, then uncomment this below block and
# set "<VALUE>" to "master". Similarly, if you want to use the images
# generated from the HEAD of the "voltha-2.1" git branches, then uncomment
# this block and replace "<VALUE>" with "voltha-2.1".
defaults:
  image_tag: master
  image_pullPolicy: Always

private_etcd_cluster: false
private_kafka_cluster: false

# OPENONU-ADAPTER IMPLEMENTATION
# ------------------------------
# There are currently two implementations of OPENONU-ADAPTER: the original
# written in Python and the reimplementation written in Go. The variable
# `use_openonu_adapter_go` can be used to optionally use the new Go
# implementation. This is done by setting that value to `true`.
#
# Along with this change you will also may need to set the Docker image
# information below (search for START_OPENONU_ADAPTER_GO).
use_openonu_adapter_go: false

images:
  onos:
    repository: voltha/voltha-onos
    # IMAGE_SELECTION
    # ---------------
    # The helm chart used to deploy ONOS is the public ONOS helm chart so,
    # there is a need to specify the exact image repository and image tag.
    # If you would like to use the "master", "voltha-2.1", or other image
    # just replace the "tag" value below.
    tag: master

# IMAGE_SELECTION
# ---------------
# Below are a list of all the images utilized by kind-voltha. This list is
# provided as a conveinence if you would like to override on a per image
# basis. If you are using the defaults, master, or voltha-2.1 branch there
# is no need to utilize this list.
#  adapter_open_olt:
#    repository: etrirepository/voltha-openolt-adapter
#    tag: dev
  adapter_open_onu:
    repository: ywra/voltha-openonu-adapter
    tag: dev
#  adapter_simulated_olt:
#    repository: voltha/voltha-adapter-simulated-olt
#    tag: 2.1.1
#  adapter_simulated_onu:
#    repository: voltha/voltha-adapter-simulated-onu
#    tag: 2.1.1
  bbsim:
    repository: ywra/bbsim
    tag: dev
#  ofagent:
#    repository: etrirepository/voltha-ofagent-go
#    tag: dev
#  rw_core:
#    repository: etrirepository/voltha-rw-core
#    tag: dev
# START_OPENONU_ADAPTER_GO - Uncomment the following block to use the
# Go implementation of the openonu-adapter
#  adapter_open_onu_go:
#    repository: voltha-openonu-adapter-go
#    tag: master
# END_OPENONU_ADAPTER_GO

etcd:
  extraEnv:
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "1"
    - name: ETCD_SNAPSHOT_COUNT
      value: "100000"
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "100"
    - name: ETCD_ELECTION_TIMEOUT
      value: "1000"
    - name: ETCD_MAX_SNAPSHOTS
      value: "5"
    - name: ETCD_QUOTA_BACKEND_BYTES
      value: "0"
    - name: ETCD_MAX_REQUEST_BYTES
      value: "1572864"
    - name: ETCD_GRPC_KEEPALIVE_MIN_TIME
      value: "5s"
    - name: ETCD_GRPC_KEEPALIVE_TIMEOUT
      value: "5s"
    - name: ETCD_DEBUG
      value: "false"

kafka:
  zookeeper:
    persistence:
      enabled: false
  persistence:
    enabled: false
  envOverrides:
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # yamllint disable-line rule:line-length
    KAFKA_LOG4J.LOGGERS: "kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka=ERROR,kafka.controller=ERROR"
    KAFKA_LOG_RETENTION_HOURS: 1
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# voltha:
#   fullNameOverride: voltha

# open-olt:
#   fullNameOverride: voltha-adapter-openolt

# open-onu:
#   fullNameOverride: voltha-adapter-openonu

onos:
  image:
    repository: voltha/voltha-onos
    tag: master
    pullPolicy: Always
  onos_env:
    - name: POD_IP
      valueFrom:
      fieldRef:
        fieldPath: status.podIP
    - name: NAMESPACE
      valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
    - name: ONOS_APPS
      value: "drivers,openflow-base,hostprovider"
  apps:
    - org.onosproject.lldpprovider
    - org.onosproject.openflow-base
    - org.onosproject.gui2
    - org.onosproject.drivers
    - org.onosproject.mcast
    - org.opencord.kafka
    - org.opencord.sadis
    - org.opencord.dhcpl2relay
    - org.opencord.maclearner
    - org.opencord.igmpproxy
    - org.opencord.mcast
    - org.opencord.olt
    - org.opencord.aaa
  # No persistent volume in Atomix to have clean state for each re-deploy of ONOS
  atomix:
    persistence:
      enabled: false

# Customization for BBSIM
bbsim:
  nni: 1
  pon: 1
  onu: 1
  sadisFormat: "att"
  kafkaEventTopic: "bbsim"
  enableEvents: false

# Customization for BBSIM SADIS Servier
sadis:
  config:
    bbsim_sadis_server:
      sleep_time: 5s

# START EFK Setup to push voltha logs
# elasticstack config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/elasticsearch
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  # set cpu and memory configuration
  resources:
    requests:
      cpu: "400m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  # setup persistence volume.By default persistence volumeclaim is disabled
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 5Gi
  persistence:
    enabled: false
  # setup cluster health status as yellow
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

# kibana config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/kibana
kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"

# fluentd-elasticsearch config
# ref: https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch
fluentd-elasticsearch:
  elasticsearch:
    # set elasticsearch host
    hosts: ["elasticsearch-master:9200"]
    sslVerify: false

# Increase maxTraces to retain Traces for longer duration
# But tracing pod will consume more memory
tracing:
  maxTraces: 500000

# SHOCK THE MONKEY OR LET LOSE THE DOGS OF WAR
# The VOLTHA charts have support for adding extra labels to deployments and
# pods. These extra labels can be used to integrate with other utilities
# such as kube-monkey to add a bit of chaos to the cluster. Below are some
# settings that can be uncommented to opt-in VOLTHA deployments/pods to
# kube-monkey. For example, if you want ALL deployments and pods to opt-in
# then uncomment the `extra_deployment_labels` and `extra_pod_label` blocks.
# If you want to be more selected then comment the blocks that pertain to the
# targets you care about.

# extra_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# extra_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
config:
  bbsim_sadis_server:
    sleep_time: 5s
+ helm install -f /tmp/tmp.45UGZmCjLe --create-namespace --set defaults.image_tag=null,images.onos.tag=4.1.4 --set defaults.log_level=WARN --namespace voltha --set defaults.image_tag=null,images.onos.tag=4.1.4 bbsim-sadis-server bbsim-sadis/bbsim-sadis-server
NAME: bbsim-sadis-server
LAST DEPLOYED: Mon Nov 30 11:35:13 2020
NAMESPACE: voltha
STATUS: deployed
REVISION: 1
TEST SUITE: None
+ curl -sSL --user karaf:karaf -w '%{http_code}' -o /tmp/tmp.Bv9ZMOfYpo -X POST --fail -H Content-Type:application/json http://127.0.0.1:8181/onos/v1/network/configuration/apps/org.opencord.sadis --data '{"sadis":{"integration":{"url":"http://bbsim-sadis-server.voltha.svc:58080/subscribers/%s","cache":{"enabled":true,"maxsize":50,"ttl":"PT1m"}}},"bandwidthprofile":{"integration":{"url":"http://bbsim-sadis-server.voltha.svc:58080/profiles/%s","cache":{"enabled":true,"maxsize":50,"ttl":"PT1m"}}}}'
RESPONSE CODE: 200
ERROR CODE: 0
---
# Copyright 2019 Ciena Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# IMAGE SELECTION
# ---------------
# By default no defaults are set and the image tags specified in the helm
# charts will be used. If you would like to use the images generated from the
# HEAD of the "master" git branches, then uncomment this below block and
# set "<VALUE>" to "master". Similarly, if you want to use the images
# generated from the HEAD of the "voltha-2.1" git branches, then uncomment
# this block and replace "<VALUE>" with "voltha-2.1".
defaults:
  image_tag: master
  image_pullPolicy: Always

private_etcd_cluster: false
private_kafka_cluster: false

# OPENONU-ADAPTER IMPLEMENTATION
# ------------------------------
# There are currently two implementations of OPENONU-ADAPTER: the original
# written in Python and the reimplementation written in Go. The variable
# `use_openonu_adapter_go` can be used to optionally use the new Go
# implementation. This is done by setting that value to `true`.
#
# Along with this change you will also may need to set the Docker image
# information below (search for START_OPENONU_ADAPTER_GO).
use_openonu_adapter_go: false

images:
  onos:
    repository: voltha/voltha-onos
    # IMAGE_SELECTION
    # ---------------
    # The helm chart used to deploy ONOS is the public ONOS helm chart so,
    # there is a need to specify the exact image repository and image tag.
    # If you would like to use the "master", "voltha-2.1", or other image
    # just replace the "tag" value below.
    tag: master

# IMAGE_SELECTION
# ---------------
# Below are a list of all the images utilized by kind-voltha. This list is
# provided as a conveinence if you would like to override on a per image
# basis. If you are using the defaults, master, or voltha-2.1 branch there
# is no need to utilize this list.
#  adapter_open_olt:
#    repository: etrirepository/voltha-openolt-adapter
#    tag: dev
  adapter_open_onu:
    repository: ywra/voltha-openonu-adapter
    tag: dev
#  adapter_simulated_olt:
#    repository: voltha/voltha-adapter-simulated-olt
#    tag: 2.1.1
#  adapter_simulated_onu:
#    repository: voltha/voltha-adapter-simulated-onu
#    tag: 2.1.1
  bbsim:
    repository: ywra/bbsim
    tag: dev
#  ofagent:
#    repository: etrirepository/voltha-ofagent-go
#    tag: dev
#  rw_core:
#    repository: etrirepository/voltha-rw-core
#    tag: dev
# START_OPENONU_ADAPTER_GO - Uncomment the following block to use the
# Go implementation of the openonu-adapter
#  adapter_open_onu_go:
#    repository: voltha-openonu-adapter-go
#    tag: master
# END_OPENONU_ADAPTER_GO

etcd:
  extraEnv:
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "1"
    - name: ETCD_SNAPSHOT_COUNT
      value: "100000"
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "100"
    - name: ETCD_ELECTION_TIMEOUT
      value: "1000"
    - name: ETCD_MAX_SNAPSHOTS
      value: "5"
    - name: ETCD_QUOTA_BACKEND_BYTES
      value: "0"
    - name: ETCD_MAX_REQUEST_BYTES
      value: "1572864"
    - name: ETCD_GRPC_KEEPALIVE_MIN_TIME
      value: "5s"
    - name: ETCD_GRPC_KEEPALIVE_TIMEOUT
      value: "5s"
    - name: ETCD_DEBUG
      value: "false"

kafka:
  zookeeper:
    persistence:
      enabled: false
  persistence:
    enabled: false
  envOverrides:
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # yamllint disable-line rule:line-length
    KAFKA_LOG4J.LOGGERS: "kafka.zookeeper=ERROR,state.change.logger=ERROR,kafka=ERROR,kafka.controller=ERROR"
    KAFKA_LOG_RETENTION_HOURS: 1
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# voltha:
#   fullNameOverride: voltha

# open-olt:
#   fullNameOverride: voltha-adapter-openolt

# open-onu:
#   fullNameOverride: voltha-adapter-openonu

onos:
  image:
    repository: voltha/voltha-onos
    tag: master
    pullPolicy: Always
  onos_env:
    - name: POD_IP
      valueFrom:
      fieldRef:
        fieldPath: status.podIP
    - name: NAMESPACE
      valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
    - name: ONOS_APPS
      value: "drivers,openflow-base,hostprovider"
  apps:
    - org.onosproject.lldpprovider
    - org.onosproject.openflow-base
    - org.onosproject.gui2
    - org.onosproject.drivers
    - org.onosproject.mcast
    - org.opencord.kafka
    - org.opencord.sadis
    - org.opencord.dhcpl2relay
    - org.opencord.maclearner
    - org.opencord.igmpproxy
    - org.opencord.mcast
    - org.opencord.olt
    - org.opencord.aaa
  # No persistent volume in Atomix to have clean state for each re-deploy of ONOS
  atomix:
    persistence:
      enabled: false

# Customization for BBSIM
bbsim:
  nni: 1
  pon: 1
  onu: 1
  sadisFormat: "att"
  kafkaEventTopic: "bbsim"
  enableEvents: false

# Customization for BBSIM SADIS Servier
sadis:
  config:
    bbsim_sadis_server:
      sleep_time: 5s

# START EFK Setup to push voltha logs
# elasticstack config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/elasticsearch
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  # set cpu and memory configuration
  resources:
    requests:
      cpu: "400m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  # setup persistence volume.By default persistence volumeclaim is disabled
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 5Gi
  persistence:
    enabled: false
  # setup cluster health status as yellow
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

# kibana config
# ref: https://github.com/elastic/helm-charts/tree/7.7.0/kibana
kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"

# fluentd-elasticsearch config
# ref: https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch
fluentd-elasticsearch:
  elasticsearch:
    # set elasticsearch host
    hosts: ["elasticsearch-master:9200"]
    sslVerify: false

# Increase maxTraces to retain Traces for longer duration
# But tracing pod will consume more memory
tracing:
  maxTraces: 500000

# SHOCK THE MONKEY OR LET LOSE THE DOGS OF WAR
# The VOLTHA charts have support for adding extra labels to deployments and
# pods. These extra labels can be used to integrate with other utilities
# such as kube-monkey to add a bit of chaos to the cluster. Below are some
# settings that can be uncommented to opt-in VOLTHA deployments/pods to
# kube-monkey. For example, if you want ALL deployments and pods to opt-in
# then uncomment the `extra_deployment_labels` and `extra_pod_label` blocks.
# If you want to be more selected then comment the blocks that pertain to the
# targets you care about.

# extra_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# extra_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# rw_core_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# ofagent_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# openonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simolt_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_deployment_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
#
# simonu_pod_labels:
#   kube-monkey/enabled: enabled
#   kube-monkey/identifier: monkey-victim
#   kube-monkey/mtbf: 1
#   kube-monkey/kill-mode: fixed
#   kube-monkey/kill-value: 1
+ helm install -f /tmp/tmp.ScmIFaM5qd --create-namespace --set defaults.log_level=WARN --namespace default --version 1.0.1 --set defaults.image_tag=null,images.onos.tag=4.1.4 radius onf/freeradius
NAME: radius
LAST DEPLOYED: Mon Nov 30 11:35:27 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
+ curl --fail -sSL --user karaf:karaf -X POST http://127.0.0.1:8181/onos/v1/network/configuration/apps/org.opencord.aaa -H Content-type:application/json -d@-
+ sed -e s/:RADIUS_SVC:/radius-freeradius.default.svc/g -e s/:RADIUS_PORT:/1812/ onos-files/onos-aaa.json
+ mkdir -p /home/delta/.volt
+ voltctl -k localhost:9092 -s localhost:55555 -e localhost:2379 config
Please issue the following commands in your terminal to ensure that you
are accessing the correct Kubernetes/Kind cluster as well as have the  
tools required by VOLTHA in your command path.                         

export VOLTCONFIG="/home/delta/.volt/config-minimal"
export PATH=/home/delta/kind-voltha/bin:$PATH

Thank you for choosing kind-voltha for you quick cluster needs.
